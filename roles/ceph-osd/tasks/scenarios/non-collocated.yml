---
- name: scenario 2 - osds round-robin their journals on dedicated devices
  fail:
    msg: "OSD scenario {{ osd_scenario }} is not non-collocated"
  when: not non_collocated

# ceph.service does not appear to be configured anymore.  Need to find a
# way to ensure idempotency on the devices and dedicated_devices with
# respect to osd_provision boolean variable.

# Each OSD device in the devices list has a corresponding journal device in
# the dedicated_devices list.  Use round-robin to fill up the remaining
# entries in the dedicated_devices to match the entries in the devices list.
#
# For example, assuming the devices list has these entries on a system
# devices: [ /dev/sdt, /dev/sdu, /dev/sdv, /dev/sdw, /dev/sdx ]
# On this system, it has two SSD disks
# dedicated_devices: [ /dev/sdb, /dev/sdc ]
#
# In this use case, we need to add three more entries to dedicated_devices:
# dedicated_devices: [ /dev/sdb, /dev/sdc, /dev/sdb, /dev/sdc, /dev/sdb ]
#
# Each distinct device in dedicated_devices can only be used up to the ratio
# set in the osd_data_journal_ratio tunable.
- name: set_fact journal_cnt temporary variable for populating dedicated_devices list
  set_fact:
    journal_cnt: "{{ dedicated_devices|length|int }}"

# These devices in the devices list are used to create file systems that
# store the OSD data.
# devices:
#   - "/dev/sdt"
#   - "/dev/sdu"
#   - "/dev/sdv"
#   - "/dev/sdw"
#   - "/dev/sdx"
#
# The dedicated_devices list has the list of devices for the OSD journals.
# A journal disk is shared with certain number of OSD data.  Assuming that
# there are two SSD disks that are picked as journal disks.
# dedicated_devices:
#   - "/dev/sdb"
#   - "/dev/sdc"
#
# The 'ceph-disk prepare' handles the creation of a journal partition with
# the size specified by the journal_size tunable in the ceph.conf file.
#
# This task loops over the devices list and fill in the missing journal disk
# in the dedicated_devices.  The round-robin method is used.
# dedicated_devices:
#   - "/dev/sdb"
#   - "/dev/sdc"
#   - "/dev/sdb"
#   - "/dev/sdc"
#   - "/dev/sdb"
- name: set_fact dedicated_devices assign a journal device to each osd
  set_fact:
    dedicated_devices: "{{ dedicated_devices }} + [ '{{ dedicated_devices[ item.0 % journal_cnt|int ] }}' ]"
  with_indexed_items: "{{ devices }}"
  when:
    - dedicated_devices|length < devices|length

- name: entries in devices and dedicated_devices lists are the same
  fail:
    msg: "Entries in devices and dedicated_devices are not the same"
  when:
    - devices|length != dedicated_devices|length

# use shell rather than docker module
# to ensure osd disk prepare finishes before
# starting the next task
- name: prepare ceph "{{ osd_objectstore }}" containerized osd disk(s) non-collocated
  shell: |
    docker run --net=host \
    --rm \
    --pid=host \
    --privileged=true \
    --name=ceph-osd-prepare-{{ ansible_hostname }}-{{ item.1 | basename }} \
    -v /etc/ceph:/etc/ceph \
    -v /var/lib/ceph/:/var/lib/ceph/ \
    -v /dev:/dev \
    -v /etc/localtime:/etc/localtime:ro \
    -e DEBUG=verbose \
    -e CLUSTER={{ cluster }} \
    -e CEPH_DAEMON=OSD_CEPH_DISK_PREPARE \
    -e OSD_DEVICE={{ item.1 }} \
    -e OSD_JOURNAL={{ item.2 }} \
    {{ docker_env_args }} \
    {{ ceph_osd_docker_prepare_env }} \
    {{ ceph_docker_registry }}/{{ ceph_docker_image }}:{{ ceph_docker_image_tag }}
  with_together:
    - "{{ parted_results.results | default([]) }}"
    - "{{ devices }}"
    - "{{ dedicated_devices }}"
  when:
    - containerized_deployment
    - osd_objectstore == 'filestore'
    - not item.0.get("skipped")
    - item.0.get("rc", 0) != 0

- name: prepare ceph "{{ osd_objectstore }}" containerized osd disk(s) non-collocated with a dedicated device for db and wal
  shell: |
    docker run --net=host \
    --rm \
    --pid=host \
    --privileged=true \
    --name=ceph-osd-prepare-{{ ansible_hostname }}-{{ item.1 | basename }} \
    -v /etc/ceph:/etc/ceph \
    -v /var/lib/ceph/:/var/lib/ceph/ \
    -v /dev:/dev \
    -v /etc/localtime:/etc/localtime:ro \
    -e DEBUG=verbose \
    -e CLUSTER={{ cluster }} \
    -e CEPH_DAEMON=OSD_CEPH_DISK_PREPARE \
    -e OSD_DEVICE={{ item.1 }} \
    -e OSD_BLUESTORE_BLOCK_DB={{ item.2 }} \
    -e OSD_BLUESTORE_BLOCK_WAL={{ item.3 }} \
    {{ docker_env_args }} \
    {{ ceph_osd_docker_prepare_env }} \
    {{ ceph_docker_registry }}/{{ ceph_docker_image }}:{{ ceph_docker_image_tag }}
  with_together:
    - "{{ parted_results.results | default([]) }}"
    - "{{ devices }}"
    - "{{ dedicated_devices }}"
    - "{{ bluestore_wal_devices }}"
  when:
    - containerized_deployment
    - osd_objectstore == 'bluestore'
    - not item.0.get("skipped")
    - item.0.get("rc", 0) != 0

- name: prepare ceph "{{ osd_objectstore }}" non-containerized osd disk(s) non-collocated
  command: "ceph-disk prepare {{ ceph_disk_cli_options }} {{ item.1 }} {{ item.2 }}"
  with_together:
    - "{{ parted_results.results | default([]) }}"
    - "{{ devices }}"
    - "{{ dedicated_devices }}"
  changed_when: false
  when:
    - osd_objectstore == 'filestore'
    - not containerized_deployment
    - not item.0.get("skipped")
    - item.0.get("rc", 0) != 0

- name: manually prepare ceph "{{ osd_objectstore }}" non-containerized osd disk(s) with a dedicated device for db and wal
  command: "ceph-disk prepare {{ ceph_disk_cli_options }} --block.db {{ item.1 }} --block.wal {{ item.2 }} {{ item.3 }}"
  with_together:
    - "{{ parted_results.results | default([]) }}"
    - "{{ dedicated_devices }}"
    - "{{ bluestore_wal_devices }}"
    - "{{ devices | unique }}"
  when:
    - osd_objectstore == 'bluestore'
    - not containerized_deployment
    - not item.0.get("skipped")
    - item.0.get("rc", 0) != 0
